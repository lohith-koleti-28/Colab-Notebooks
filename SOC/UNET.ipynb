{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMZdSBpBWc08CXm1FD6zVOz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Model**"],"metadata":{"id":"Zc_BmMKY1g4V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyG6dAYVstjT","collapsed":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms.functional as TF\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNET(nn.Module):\n","    def __init__(\n","            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n","    ):\n","        super(UNET, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down part of UNET\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up part of UNET\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(\n","                    feature*2, feature, kernel_size=2, stride=2,\n","                )\n","            )\n","            self.ups.append(DoubleConv(feature*2, feature))\n","\n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx//2]\n","\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx+1](concat_skip)\n","\n","        return self.final_conv(x)\n","\n","def test():\n","    x = torch.randn((3, 1, 161, 161))\n","    model = UNET(in_channels=1, out_channels=1)\n","    preds = model(x)\n"]},{"cell_type":"markdown","source":["# **Dataset**"],"metadata":{"id":"lSaYyjmc1sUf"}},{"cell_type":"code","source":["import os\n","from PIL import ImageChops\n","from torch.utils.data import Dataset\n","import numpy as np\n","\n","class CarvanaDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.images = os.listdir(image_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.image_dir, self.images[index])\n","        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.gif\"))\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n","        mask[mask == 255.0] = 1.0\n","\n","        if self.transform is not None:\n","          augmentations = self.transform(image=image, mask=mask)\n","          image = augmentations[\"image\"]\n","          mask = augmentations[\"mask\"]\n","\n","        return image, mask\n"],"metadata":{"id":"h3gRpp4X1gNy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Utils File**"],"metadata":{"id":"lK-d_Lq_3y0x"}},{"cell_type":"code","source":["#Utils file begins\n","\n","def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","        print(\"=> Saving checkpoint\")\n","        torch.save(state, filename)\n","\n","def load_checkpoint(checkpoint, model):\n","        print(\"=> Loading checkpoint\")\n","        model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","def get_loaders(\n","        train_dir,\n","        train_maskdir,\n","        val_dir,\n","        val_maskdir,\n","        batch_size,\n","        train_transform,\n","        val_transform,\n","        num_workers=4,\n","        pin_memory=True,\n","    ):\n","        train_ds = CarvanaDataset(\n","            image_dir=train_dir,\n","            mask_dir=train_maskdir,\n","            transform=train_transform,\n","        )\n","\n","        train_loader = DataLoader(\n","            train_ds,\n","            batch_size=batch_size,\n","            num_workers=num_workers,\n","            pin_memory=pin_memory,\n","            shuffle=True,\n","        )\n","\n","        val_ds = CarvanaDataset(\n","            image_dir=val_dir,\n","            mask_dir=val_maskdir,\n","            transform=val_transform,\n","        )\n","\n","        val_loader = DataLoader(\n","            val_ds,\n","            batch_size=batch_size,\n","            num_workers=num_workers,\n","            pin_memory=pin_memory,\n","            shuffle=False,\n","        )\n","\n","        return train_loader, val_loader\n","\n","def check_accuracy(loader, model, device=\"cuda\"):\n","        num_correct = 0\n","        num_pixels = 0\n","        dice_score = 0\n","        model.eval()\n","\n","        with torch.no_grad():\n","            for x, y in loader:\n","                x = x.to(device)\n","                y = y.to(device).unsqueeze(1)\n","                preds = torch.sigmoid(model(x))\n","                preds = (preds > 0.5).float()\n","                num_correct += (preds == y).sum()\n","                num_pixels += torch.numel(preds)\n","                dice_score += (2 * (preds * y).sum()) / (\n","                    (preds + y).sum() + 1e-8\n","                )\n","\n","        print(\n","            f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n","        )\n","        print(f\"Dice score: {dice_score/len(loader)}\")\n","        model.train()\n","\n","def save_predictions_as_imgs(\n","        loader, model, folder=\"saved_images/\", device=\"cuda\"\n","    ):\n","        model.eval()\n","        for idx, (x, y) in enumerate(loader):\n","            x = x.to(device=device)\n","            with torch.no_grad():\n","                preds = torch.sigmoid(model(x))\n","                preds = (preds > 0.5).float()\n","            torchvision.utils.save_image(\n","                preds, f\"{folder}/pred_{idx}.png\"\n","            )\n","            torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n","\n","        model.train()"],"metadata":{"id":"qt3cM_5c-U81"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Tranning**"],"metadata":{"id":"PpwxPJvL_D0r"}},{"cell_type":"code","source":["import torch.optim as optim\n","import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","learning_rate = 1e-4\n","batch_size = 16\n","num_epochs = 3\n","num_workers = 2\n","img_height = 160\n","img_width = 240\n","pin_memory = True\n","load_model = True\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_image_dir = \"/content/drive/MyDrive/Carvana/train_images\"\n","train_mask_dir = \"/content/drive/MyDrive/Carvana/train_masks\"\n","val_image_dir = \"/content/drive/MyDrive/Carvana/val_images\"\n","val_mask_dir = \"/content/drive/MyDrive/Carvana/val_masks\"\n","\n","\n","def train_fn(loader, model, optimizer, loss_fn, scaler):\n","    loop = tqdm(loader)\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=device)\n","        targets = targets.float().unsqueeze(1).to(device=device)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # update tqdm loop\n","        loop.set_postfix(loss=loss.item())\n","\n","def main():\n","    train_transform = A.Compose(\n","        [\n","            A.Resize(height=img_height, width=img_width),\n","            A.Rotate(limit=35, p=1.0),\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.1),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    val_transforms = A.Compose(\n","        [\n","            A.Resize(height=img_height, width=img_width),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    model = UNET(in_channels=3, out_channels=1).to(device)\n","    loss_fn = nn.BCEWithLogitsLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    train_loader, val_loader = get_loaders(\n","        train_dir=train_image_dir,\n","        train_maskdir=train_mask_dir,\n","        val_dir=val_image_dir,\n","        val_maskdir=val_mask_dir,\n","        batch_size=batch_size,\n","        train_transform=train_transform,\n","        val_transform=val_transforms,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","    )\n","\n","    scaler = torch.cuda.amp.GradScaler()\n","    for epoch in range(num_epochs):\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","\n","        #save model\n","        checkpoint = {\n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\": optimizer.state_dict(),\n","        }\n","        save_checkpoint(checkpoint)\n","\n","        #Check Accuracy\n","        check_accuracy(val_loader, model, device)\n","\n","        #Save some images\n","        save_predictions_as_imgs(\n","            val_loader, model, folder=\"saved_images/\", device=device\n","        )\n","\n","main()\n","\n"],"metadata":{"id":"ejV9msrl32qu"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1f9mzdXnCpXBWNIoFcGg1uO5ah2b9jivA","authorship_tag":"ABX9TyOS9uuP8OAzbXbL/4p/zUZk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"XErghQhD-LAc","executionInfo":{"status":"ok","timestamp":1720705451950,"user_tz":-330,"elapsed":529,"user":{"displayName":"Integration S","userId":"03211167078800808410"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","import os\n","\n","#Hyperparameters\n","BATCH_SIZE = 32\n","IMG_SIZE = 64\n","TRAIN_SPLIT = 0.9\n","DATA_DIR = '/content/drive/MyDrive/homer_bart'\n","\n","#Data Preprossing\n","transform = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor()\n","])\n","\n","dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n","train_size = int(TRAIN_SPLIT * len(dataset))\n","test_size = len(dataset) - train_size\n","\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","#NN\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(IMG_SIZE * IMG_SIZE * 3, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 200)\n","        self.fc4 = nn.Linear(200, 128)\n","        self.fc5 = nn.Linear(128, 1)\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))\n","        x = self.relu(self.fc4(x))\n","        x = self.sigmoid(self.fc5(x))\n","        return x"]},{"cell_type":"code","source":["model = SimpleNN()\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for inputs, labels in train_loader:\n","        labels = labels.float().unsqueeze(1)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    if (epoch+1) % 100 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7mxhjT3BECM","executionInfo":{"status":"ok","timestamp":1720708082015,"user_tz":-330,"elapsed":188494,"user":{"displayName":"Integration S","userId":"03211167078800808410"}},"outputId":"656176be-380a-4ace-a9a0-33a6d4a2f50e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [100/100], Loss: 0.0042\n"]}]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        labels = labels.float().unsqueeze(1)\n","        outputs = model(inputs)\n","        predicted = (outputs > 0.5).float()\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","if accuracy > 0.9:\n","    print(\"Test Accuracy is greater than 90%.\")\n","else:\n","    print(\"Test Accuracy is less than 90%.\")\n"],"metadata":{"id":"YuD6nvwxAOyz"},"execution_count":null,"outputs":[]}]}